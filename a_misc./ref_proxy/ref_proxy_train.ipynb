{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e17b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>source</th>\n",
       "      <th>candidate</th>\n",
       "      <th>target_score</th>\n",
       "      <th>sts_with_source</th>\n",
       "      <th>len_ratio_chars</th>\n",
       "      <th>len_ratio_words</th>\n",
       "      <th>abs_len_words</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>avg_syl_per_word</th>\n",
       "      <th>sentence_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-a2</td>\n",
       "      <td>Now NASA is working towards logging some of th...</td>\n",
       "      <td>NASA is now trying to find smaller asteroids. ...</td>\n",
       "      <td>0.8410</td>\n",
       "      <td>0.7641</td>\n",
       "      <td>0.843823</td>\n",
       "      <td>0.938272</td>\n",
       "      <td>76</td>\n",
       "      <td>72.889068</td>\n",
       "      <td>1.197368</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-b1</td>\n",
       "      <td>Now NASA is working towards logging some of th...</td>\n",
       "      <td>NASA is now trying to record some of the small...</td>\n",
       "      <td>0.8480</td>\n",
       "      <td>0.8374</td>\n",
       "      <td>0.979021</td>\n",
       "      <td>1.049383</td>\n",
       "      <td>85</td>\n",
       "      <td>71.772459</td>\n",
       "      <td>1.235294</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02-a2</td>\n",
       "      <td>Earthquakes damage all structures, including b...</td>\n",
       "      <td>Earthquakes can break things, like bridges. Lu...</td>\n",
       "      <td>0.7825</td>\n",
       "      <td>0.6584</td>\n",
       "      <td>0.787402</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>37</td>\n",
       "      <td>73.540215</td>\n",
       "      <td>1.216216</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02-b1</td>\n",
       "      <td>Earthquakes damage all structures, including b...</td>\n",
       "      <td>Earthquakes can damage all buildings, includin...</td>\n",
       "      <td>0.9453</td>\n",
       "      <td>0.8578</td>\n",
       "      <td>0.877953</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>39</td>\n",
       "      <td>54.670000</td>\n",
       "      <td>1.410256</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03-a2</td>\n",
       "      <td>The Hunger Games are an annual event, which th...</td>\n",
       "      <td>The Hunger Games happen every year. The Capito...</td>\n",
       "      <td>0.6548</td>\n",
       "      <td>0.8438</td>\n",
       "      <td>0.853018</td>\n",
       "      <td>0.907895</td>\n",
       "      <td>69</td>\n",
       "      <td>79.274506</td>\n",
       "      <td>1.188406</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  text_id                                             source  \\\n",
       "0   01-a2  Now NASA is working towards logging some of th...   \n",
       "1   01-b1  Now NASA is working towards logging some of th...   \n",
       "2   02-a2  Earthquakes damage all structures, including b...   \n",
       "3   02-b1  Earthquakes damage all structures, including b...   \n",
       "4   03-a2  The Hunger Games are an annual event, which th...   \n",
       "\n",
       "                                           candidate  target_score  \\\n",
       "0  NASA is now trying to find smaller asteroids. ...        0.8410   \n",
       "1  NASA is now trying to record some of the small...        0.8480   \n",
       "2  Earthquakes can break things, like bridges. Lu...        0.7825   \n",
       "3  Earthquakes can damage all buildings, includin...        0.9453   \n",
       "4  The Hunger Games happen every year. The Capito...        0.6548   \n",
       "\n",
       "   sts_with_source  len_ratio_chars  len_ratio_words  abs_len_words  \\\n",
       "0           0.7641         0.843823         0.938272             76   \n",
       "1           0.8374         0.979021         1.049383             85   \n",
       "2           0.6584         0.787402         0.880952             37   \n",
       "3           0.8578         0.877953         0.928571             39   \n",
       "4           0.8438         0.853018         0.907895             69   \n",
       "\n",
       "   flesch_reading_ease  avg_syl_per_word  sentence_count  \n",
       "0            72.889068          1.197368               8  \n",
       "1            71.772459          1.235294               5  \n",
       "2            73.540215          1.216216               3  \n",
       "3            54.670000          1.410256               3  \n",
       "4            79.274506          1.188406               6  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb√ü\n",
    "\n",
    "# --- Configuration ---\n",
    "PROCESSED_DATA_FILE = 'proxy_training_data.csv'\n",
    "MODEL_OUTPUT_FILE = 'reference_proxy_model.joblib'\n",
    "RESULTS_OUTPUT_FILE = 'grid_search_results.csv'\n",
    "# --- End Configuration ---\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(PROCESSED_DATA_FILE)\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ebf2620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 7 features for 1601 samples.\n"
     ]
    }
   ],
   "source": [
    "feature_columns = [\n",
    "    'sts_with_source', 'len_ratio_chars', 'len_ratio_words', \n",
    "    'abs_len_words', 'flesch_reading_ease', 'avg_syl_per_word', \n",
    "    'sentence_count'\n",
    "]\n",
    "target_column = 'target_score'\n",
    "\n",
    "X = df[feature_columns]\n",
    "y = df[target_column]\n",
    "\n",
    "print(f\"Using {len(feature_columns)} features for {len(X)} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "863bec97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will define a list of models and their corresponding parameter grids\n",
    "models_to_search = [\n",
    "    {\n",
    "        'name': 'Ridge',\n",
    "        'estimator': Ridge(),\n",
    "        'params': {\n",
    "            'alpha': [0.1, 1.0, 10.0, 100.0]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'XGBoost',\n",
    "        'estimator': XGBRegressor(random_state=42),\n",
    "        'params': {\n",
    "            'n_estimators': [100, 200],\n",
    "            'learning_rate': [0.05, 0.1],\n",
    "            'max_depth': [3, 5]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'LightGBM',\n",
    "        'estimator': lgb.LGBMRegressor(random_state=42),\n",
    "        'params': {\n",
    "            'n_estimators': [100, 200],\n",
    "            'learning_rate': [0.05, 0.1],\n",
    "            'num_leaves': [20, 31]\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cd989d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Grid Search with 5-fold Cross-Validation...\n",
      "--- Tuning model: Ridge ---\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "--- Tuning model: XGBoost ---\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "--- Tuning model: LightGBM ---\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.395627 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1391\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.485575 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.371649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1391\n",
      "[LightGBM] [Info] Number of data points in the train set: 1281, number of used features: 7\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.442637 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1392\n",
      "[LightGBM] [Info] Number of data points in the train set: 1280, number of used features: 7\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.421624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1391\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.414597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1391\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.443657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1392\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.409649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1394\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.506553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1392\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.506624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 1281, number of used features: 7\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.410396 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.452645 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1391\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.456626 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.464637 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1391\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.399642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 1281, number of used features: 7\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.517676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1391\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.431664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1391\n",
      "[LightGBM] [Info] Number of data points in the train set: 1281, number of used features: 7\n",
      "[LightGBM] [Info] Number of data points in the train set: 1280, number of used features: 7\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.471866 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1394\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.461641 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1392\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.423648 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1394\n",
      "[LightGBM] [Info] Number of data points in the train set: 1281, number of used features: 7\n",
      "[LightGBM] [Info] Number of data points in the train set: 1281, number of used features: 7\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.502448 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1391\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.443664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1391\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.457655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 1281, number of used features: 7\n",
      "[LightGBM] [Info] Number of data points in the train set: 1281, number of used features: 7\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.538646 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1391\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.453652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1392\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.505635 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.443565 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1392\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.501664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1394\n",
      "[LightGBM] [Info] Number of data points in the train set: 1280, number of used features: 7\n",
      "[LightGBM] [Info] Number of data points in the train set: 1281, number of used features: 7\n",
      "[LightGBM] [Info] Number of data points in the train set: 1280, number of used features: 7\n",
      "[LightGBM] [Info] Number of data points in the train set: 1281, number of used features: 7\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.505640 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1391\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.522537 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1391\n",
      "[LightGBM] [Info] Start training from score 0.781994\n",
      "[LightGBM] [Info] Number of data points in the train set: 1281, number of used features: 7\n",
      "[LightGBM] [Info] Number of data points in the train set: 1281, number of used features: 7\n",
      "[LightGBM] [Info] Number of data points in the train set: 1281, number of used features: 7\n",
      "[LightGBM] [Info] Number of data points in the train set: 1281, number of used features: 7\n",
      "[LightGBM] [Info] Number of data points in the train set: 1281, number of used features: 7\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.455681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1394\n",
      "[LightGBM] [Info] Number of data points in the train set: 1280, number of used features: 7\n",
      "[LightGBM] [Info] Number of data points in the train set: 1280, number of used features: 7\n",
      "[LightGBM] [Info] Number of data points in the train set: 1281, number of used features: 7\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.485651 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1394\n",
      "[LightGBM] [Info] Number of data points in the train set: 1281, number of used features: 7\n",
      "[LightGBM] [Info] Number of data points in the train set: 1281, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 0.781340\n",
      "[LightGBM] [Info] Number of data points in the train set: 1281, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 0.781699\n",
      "[LightGBM] [Info] Start training from score 0.781750\n",
      "[LightGBM] [Info] Number of data points in the train set: 1280, number of used features: 7[LightGBM] [Info] Number of data points in the train set: 1281, number of used features: 7\n",
      "\n",
      "[LightGBM] [Info] Number of data points in the train set: 1281, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 0.781369\n",
      "[LightGBM] [Info] Number of data points in the train set: 1281, number of used features: 7\n",
      "[LightGBM] [Info] Number of data points in the train set: 1281, number of used features: 7\n",
      "[LightGBM] [Info] Number of data points in the train set: 1281, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 0.781369\n",
      "[LightGBM] [Info] Number of data points in the train set: 1281, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 0.781699\n",
      "[LightGBM] [Info] Start training from score 0.781994\n",
      "[LightGBM] [Info] Start training from score 0.781699\n",
      "[LightGBM] [Info] Start training from score 0.781699\n",
      "[LightGBM] [Info] Start training from score 0.781994\n",
      "[LightGBM] [Info] Start training from score 0.781340\n",
      "[LightGBM] [Info] Start training from score 0.781340\n",
      "[LightGBM] [Info] Start training from score 0.781369\n",
      "[LightGBM] [Info] Start training from score 0.781994\n",
      "[LightGBM] [Info] Start training from score 0.781340\n",
      "[LightGBM] [Info] Start training from score 0.781699\n",
      "[LightGBM] [Info] Start training from score 0.781750\n",
      "[LightGBM] [Info] Start training from score 0.781369\n",
      "[LightGBM] [Info] Start training from score 0.781369\n",
      "[LightGBM] [Info] Start training from score 0.781699\n",
      "[LightGBM] [Info] Start training from score 0.781340\n",
      "[LightGBM] [Info] Start training from score 0.781750\n",
      "[LightGBM] [Info] Start training from score 0.781994\n",
      "[LightGBM] [Info] Start training from score 0.781340\n",
      "[LightGBM] [Info] Start training from score 0.781369\n",
      "[LightGBM] [Info] Start training from score 0.781340\n",
      "[LightGBM] [Info] Start training from score 0.781994\n",
      "[LightGBM] [Info] Start training from score 0.781750\n",
      "[LightGBM] [Info] Start training from score 0.781699\n",
      "[LightGBM] [Info] Start training from score 0.781750\n",
      "[LightGBM] [Info] Start training from score 0.781750\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.127246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1391\n",
      "[LightGBM] [Info] Number of data points in the train set: 1281, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 0.781994\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.142776 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1394\n",
      "[LightGBM] [Info] Number of data points in the train set: 1281, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 0.781750\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.491408 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1392\n",
      "[LightGBM] [Info] Number of data points in the train set: 1281, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 0.781369\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.476777 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 1280, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 0.781699\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.484113 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1391\n",
      "[LightGBM] [Info] Number of data points in the train set: 1281, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 0.781340\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.472829 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1391\n",
      "[LightGBM] [Info] Number of data points in the train set: 1281, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 0.781994\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.475823 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1394\n",
      "[LightGBM] [Info] Number of data points in the train set: 1281, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 0.781750\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.477955 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1392\n",
      "[LightGBM] [Info] Number of data points in the train set: 1281, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 0.781369\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000122 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 1601, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 0.781630\n",
      "\n",
      "‚úÖ Grid Search complete!\n"
     ]
    }
   ],
   "source": [
    "# Define the cross-validation strategy\n",
    "# We use 5 splits. The data is shuffled.\n",
    "cv_strategy = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "all_results = []\n",
    "\n",
    "print(\"Starting Grid Search with 5-fold Cross-Validation...\")\n",
    "\n",
    "for model_config in models_to_search:\n",
    "    print(f\"--- Tuning model: {model_config['name']} ---\")\n",
    "    \n",
    "    # GridSearchCV will test all parameter combinations using cross-validation\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model_config['estimator'],\n",
    "        param_grid=model_config['params'],\n",
    "        cv=cv_strategy,\n",
    "        scoring='r2',  # We'll rank models by their R-squared score\n",
    "        n_jobs=-1,     # Use all available CPU cores\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit the grid search on the entire dataset\n",
    "    # It handles the internal train/validation splits automatically\n",
    "    grid_search.fit(X, y)\n",
    "    \n",
    "    # Store the results\n",
    "    result = {\n",
    "        'model_name': model_config['name'],\n",
    "        'best_score_r2': grid_search.best_score_,\n",
    "        'best_params': grid_search.best_params_\n",
    "    }\n",
    "    all_results.append(result)\n",
    "\n",
    "print(\"\\n‚úÖ Grid Search complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f59682e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search results saved to grid_search_results.csv\n",
      "\n",
      "--- Model Comparison ---\n",
      "  model_name  best_score_r2                                        best_params\n",
      "1    XGBoost       0.388698  {'learning_rate': 0.05, 'max_depth': 5, 'n_est...\n",
      "2   LightGBM       0.382549  {'learning_rate': 0.05, 'n_estimators': 100, '...\n",
      "0      Ridge       0.271309                                     {'alpha': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Sort by the best score to find the winner\n",
    "results_df = results_df.sort_values(by='best_score_r2', ascending=False)\n",
    "\n",
    "# Save the results to a CSV for your records\n",
    "results_df.to_csv(RESULTS_OUTPUT_FILE, index=False)\n",
    "\n",
    "print(f\"Grid Search results saved to {RESULTS_OUTPUT_FILE}\")\n",
    "print(\"\\n--- Model Comparison ---\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95331594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÜ Winning Model: XGBoost\n",
      "Best Hyperparameters: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100}\n",
      "\n",
      "Final model has been retrained on the full dataset.\n",
      "üíæ Final model saved to: reference_proxy_model.joblib\n"
     ]
    }
   ],
   "source": [
    "# Get the name and best parameters of the winning model\n",
    "best_model_config = results_df.iloc[0]\n",
    "best_model_name = best_model_config['model_name']\n",
    "best_params = best_model_config['best_params']\n",
    "\n",
    "print(f\"üèÜ Winning Model: {best_model_name}\")\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "\n",
    "# Find the original estimator object\n",
    "final_estimator = None\n",
    "for model_info in models_to_search:\n",
    "    if model_info['name'] == best_model_name:\n",
    "        final_estimator = model_info['estimator']\n",
    "        break\n",
    "\n",
    "# Set the best parameters and retrain on ALL data\n",
    "final_model = final_estimator.set_params(**best_params)\n",
    "final_model.fit(X, y)\n",
    "\n",
    "print(\"\\nFinal model has been retrained on the full dataset.\")\n",
    "\n",
    "# Save the final, optimized model\n",
    "joblib.dump(final_model, MODEL_OUTPUT_FILE)\n",
    "print(f\"üíæ Final model saved to: {MODEL_OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b30c050",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tsar-st)",
   "language": "python",
   "name": "tsar-st"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
